{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: Word2vec Vector Analysis\n",
    "\n",
    "*Important Note:* Start this notebook only after you've gotten your word2vec model up and running!\n",
    "\n",
    "Many NLP packages support working with word embeddings. In this notebook you can work through the various problems assigned in Task 3. We've provided the basic functionality for loading word vectors using [Gensim](https://radimrehurek.com/gensim/models/keyedvectors.html), a good library for learning and using word vectors, and for working with the vectors. \n",
    "\n",
    "One of the fun parts of word vectors is getting a sense of what they learned. Feel free to explore the vectors here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('128_y_mod', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0461919 , -0.27958593,  0.1705589 , -0.1708306 , -0.299215  ,\n",
       "        0.12586492,  0.38734227,  0.42276928, -0.02270849,  0.25883   ,\n",
       "        0.21754925,  0.27751365, -0.41322866,  0.49006552,  0.38869873,\n",
       "        0.25016734, -0.42294642,  0.18135971,  0.2857234 ,  0.35916075,\n",
       "       -0.17796668, -0.03476328,  0.23323797, -0.10583314, -0.40318093,\n",
       "       -0.6803291 , -0.11668469,  0.21437505,  0.68757534, -0.03521594,\n",
       "        0.12247027,  0.161055  , -0.68418103,  0.3738862 , -0.12861498,\n",
       "        0.1484024 , -0.23586893,  0.2550264 ,  0.22299844,  0.15001719,\n",
       "       -0.5330471 ,  0.06291709, -0.46547735, -0.11698226, -0.01000666,\n",
       "       -0.45244586, -0.20715865,  0.6267541 , -0.2788408 ,  0.5154677 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST WORD 1: book\n",
      "('seller', 0.8910008072853088)\n",
      "('item', 0.8841663002967834)\n",
      "('title', 0.8719245791435242)\n",
      "('definitely', 0.8699206113815308)\n",
      "('price', 0.8690272569656372)\n",
      "('one', 0.867672324180603)\n",
      "('cookbook', 0.8660906553268433)\n",
      "('trilogy', 0.8594567775726318)\n",
      "('volume', 0.8508355021476746)\n",
      "('ebook', 0.8436343669891357)\n",
      "TEST WORD 2: man\n",
      "('woman', 0.9894148707389832)\n",
      "('girl', 0.937923014163971)\n",
      "('boy', 0.9045149683952332)\n",
      "('dog', 0.9029589295387268)\n",
      "('named', 0.8983724117279053)\n",
      "('business', 0.8923180103302002)\n",
      "('lady', 0.8908073902130127)\n",
      "('system', 0.8904485702514648)\n",
      "('officer', 0.8883284330368042)\n",
      "('career', 0.8880956768989563)\n",
      "TEST WORD 3: movie\n",
      "('released', 0.9333871006965637)\n",
      "('continued', 0.9259529113769531)\n",
      "('pleasure', 0.9259244203567505)\n",
      "('immensely', 0.9234510064125061)\n",
      "('completed', 0.9234030842781067)\n",
      "('prequel', 0.9222213625907898)\n",
      "('hers', 0.9215497970581055)\n",
      "('sequel', 0.9210048317909241)\n",
      "('Schiff', 0.9207335114479065)\n",
      "('throughly', 0.9194551110267639)\n",
      "TEST WORD 4: write\n",
      "('call', 0.9679006934165955)\n",
      "('publish', 0.9611886739730835)\n",
      "('sell', 0.9556751251220703)\n",
      "('consider', 0.9556727409362793)\n",
      "('encourage', 0.9535279870033264)\n",
      "('ask', 0.9518495202064514)\n",
      "('choose', 0.9483559727668762)\n",
      "('cook', 0.942824125289917)\n",
      "('advise', 0.9395827651023865)\n",
      "('convince', 0.9366946220397949)\n",
      "TEST WORD 5: live\n",
      "('grow', 0.9698007106781006)\n",
      "('survive', 0.9560514092445374)\n",
      "('apply', 0.9543641209602356)\n",
      "('trust', 0.9523800015449524)\n",
      "('bring', 0.9518041610717773)\n",
      "('destroy', 0.9501946568489075)\n",
      "('kill', 0.9501027464866638)\n",
      "('share', 0.9483609199523926)\n",
      "('overcome', 0.944297194480896)\n",
      "('handle', 0.9442417025566101)\n",
      "TEST WORD 6: drink\n",
      "('educate', 0.9907675981521606)\n",
      "('blame', 0.9893016815185547)\n",
      "('steal', 0.9892415404319763)\n",
      "('shoot', 0.9884335398674011)\n",
      "('transform', 0.9877211451530457)\n",
      "('respond', 0.9871939420700073)\n",
      "('discuss', 0.9871638417243958)\n",
      "('feed', 0.9870095252990723)\n",
      "('commit', 0.986817479133606)\n",
      "('sink', 0.986552357673645)\n",
      "TEST WORD 7: eat\n",
      "('decide', 0.9726094007492065)\n",
      "('whether', 0.9701506495475769)\n",
      "('ask', 0.9645417332649231)\n",
      "('allow', 0.9604813456535339)\n",
      "('handle', 0.9570214748382568)\n",
      "('apply', 0.9568131566047668)\n",
      "('leave', 0.9550234079360962)\n",
      "('hear', 0.9545174837112427)\n",
      "('trust', 0.9536502957344055)\n",
      "('forget', 0.951421320438385)\n",
      "TEST WORD 8: pray\n",
      "('educate', 0.9910176992416382)\n",
      "('Him', 0.9904571175575256)\n",
      "('join', 0.9887081980705261)\n",
      "('pursue', 0.9878684282302856)\n",
      "('ourselves', 0.9867031574249268)\n",
      "('punish', 0.9863701462745667)\n",
      "('wishes', 0.9862005114555359)\n",
      "('contact', 0.9861981272697449)\n",
      "('seek', 0.9860595464706421)\n",
      "('heed', 0.984698474407196)\n",
      "TEST WORD 9: dream\n",
      "('honor', 0.9895876049995422)\n",
      "('dress', 0.989228367805481)\n",
      "('belief', 0.9885684847831726)\n",
      "('teams', 0.9880332350730896)\n",
      "('fame', 0.9870565533638)\n",
      "('protecting', 0.9867756366729736)\n",
      "('spirits', 0.9866868853569031)\n",
      "('vision', 0.9865455627441406)\n",
      "('worship', 0.9862181544303894)\n",
      "('goal', 0.9860354661941528)\n",
      "TEST WORD 10: war\n",
      "('United', 0.9778455495834351)\n",
      "('South', 0.977474570274353)\n",
      "('20th', 0.9752077460289001)\n",
      "('Nazi', 0.9748478531837463)\n",
      "('States', 0.9744210839271545)\n",
      "('North', 0.9734656810760498)\n",
      "('civil', 0.9728497266769409)\n",
      "('19th', 0.9701560139656067)\n",
      "('trials', 0.9682444930076599)\n",
      "('Pacific', 0.9678400158882141)\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "for test_word in ['book', 'man', 'movie', 'write', \"live\", \"drink\", \"eat\", \"pray\", \"dream\", \"war\"]:\n",
    "    print(f\"TEST WORD {counter}:\", test_word)\n",
    "    sim_words = word_vectors.similar_by_word(test_word)\n",
    "    for x in sim_words:\n",
    "        print(x)\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogy(a, b, c):\n",
    "    most_sim = word_vectors.most_similar(positive=[b, c], negative=[a])[0][0]\n",
    "    s = f\"'{a}' is to '{b}' what '{c}' is to... '{most_sim}'\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'brother' is to 'sister' what 'father' is to... 'mother'\n",
      "'Tokyo' is to 'Japan' what 'Paris' is to... 'Europe'\n",
      "'run' is to 'walk' what 'think' is to... 'realize'\n",
      "'slow' is to 'fast' what 'sad' is to... 'exciting'\n",
      "'cat' is to 'dog' what 'happy' is to... 'thrilled'\n"
     ]
    }
   ],
   "source": [
    "print(get_analogy('brother', 'sister', 'father'))\n",
    "print(get_analogy('Tokyo', 'Japan', 'Paris'))\n",
    "print(get_analogy('run', 'walk', 'think'))\n",
    "print(get_analogy('slow', 'fast', 'sad'))\n",
    "print(get_analogy('cat', 'dog', 'happy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (misinformation_sim)",
   "language": "python",
   "name": "pycharm-9607488f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
